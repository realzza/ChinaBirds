{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.model import Gvector\n",
    "import torch\n",
    "import json\n",
    "from scipy.special import softmax\n",
    "import soundfile as sf\n",
    "from python_speech_features import logfbank\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_clf_kwargs = {\n",
    "    \"channels\": 16, \n",
    "    \"block\": \"BasicBlock\", \n",
    "    \"num_blocks\": [2,2,2,2], \n",
    "    \"embd_dim\": 1024, \n",
    "    \"drop\": 0.3, \n",
    "    \"n_class\": 821\n",
    "}\n",
    "model_path = 'exp/821b_bad_aug_0.1/chkpt/chkpt_best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(mdl_kwargs, model_path, device):\n",
    "    model = Gvector(**mdl_kwargs)\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    if 'model' in state_dict.keys():\n",
    "        state_dict = state_dict['model']\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_wav = '/DATA1/ziang/data/sw/3h-aligned/AmurFalcon/149819.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVExtractor():\n",
    "    def __init__(self, mdl_kwargs, model_path, device):\n",
    "        self.model = self.load_model(mdl_kwargs, model_path, device)\n",
    "        self.model.eval()\n",
    "        self.device = device\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "    def load_model(self, mdl_kwargs, model_path, device):\n",
    "        model = Gvector(**mdl_kwargs)\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "        if 'model' in state_dict.keys():\n",
    "            state_dict = state_dict['model']\n",
    "        model.load_state_dict(state_dict)\n",
    "        return model\n",
    "\n",
    "    def __call__(self, frame_feats):\n",
    "        feat = torch.from_numpy(frame_feats).unsqueeze(0)\n",
    "        feat = feat.float().to(self.device)\n",
    "        with torch.no_grad():\n",
    "            embd = self.model(feat)\n",
    "        embd = embd.squeeze(0).cpu().numpy()\n",
    "        return embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf = SVExtractor(mdl_clf_kwargs, model_path, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feat(wav_path, to_tensor=False, cmn=True, device=\"cpu\"):\n",
    "    kwargs = {\n",
    "        \"winlen\": 0.025,\n",
    "        \"winstep\": 0.01,\n",
    "        \"nfilt\": 80,\n",
    "        \"nfft\": 2048,\n",
    "        \"lowfreq\": 50,\n",
    "        \"highfreq\": 8000,\n",
    "        \"preemph\": 0.97\n",
    "    }\n",
    "    y, sr = sf.read(wav_path)\n",
    "    logfbankFeat = logfbank(y, sr, **kwargs)\n",
    "    if cmn:\n",
    "        logfbankFeat -= logfbankFeat.mean(axis=0, keepdims=True)\n",
    "#     if to_tensor:\n",
    "#         logfbankFeat = torch.from_numpy(logfbankFeat).unsqueeze(0)\n",
    "#         return logfbankFeat.float().to(device)\n",
    "    return logfbankFeat.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_feats = extract_feat(sample_wav, to_tensor=True)\n",
    "# feats_tensor = torch.Tensor(sample_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-21.112143  , -20.329369  , -19.710909  , ..., -13.713343  ,\n",
       "        -14.4133215 , -12.876054  ],\n",
       "       [-13.920484  , -13.640373  , -13.68454   , ...,  -8.511074  ,\n",
       "         -8.854626  ,  -8.220791  ],\n",
       "       [ -6.4466815 ,  -6.4411244 ,  -6.434847  , ...,  -6.472795  ,\n",
       "         -7.208386  ,  -7.3128448 ],\n",
       "       ...,\n",
       "       [ -0.28600848,  -0.3062762 ,  -0.33613098, ...,  -2.484031  ,\n",
       "         -2.3440166 ,  -2.1353269 ],\n",
       "       [ -5.0375047 ,  -5.0419736 ,  -5.0797276 , ...,  -8.505127  ,\n",
       "         -8.492745  ,  -7.3151937 ],\n",
       "       [-10.496453  , -10.426983  , -10.33989   , ..., -11.079787  ,\n",
       "        -10.737795  ,  -9.616296  ]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(softmax(model_clf(sample_feats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992602"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(model_clf(sample_feats))[750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index-try/label2int_l1k.json','r') as f:\n",
    "    label2int = json.load(f)\n",
    "    int2label = {v:k for k,v in label2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AmurFalcon'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2label[750]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save jit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_jit = load_model(mdl_clf_kwargs, model_path, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scripted = torch.jit.script(model_jit) # Export to TorchScript\n",
    "model_scripted.eval()\n",
    "model_scripted.save('821b_jit.pt') # Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load jit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JITExtractor():\n",
    "    def __init__(self, mdl_kwargs, model_path, device):\n",
    "        self.model = self.load_model(mdl_kwargs, model_path, device)\n",
    "        self.model.eval()\n",
    "        self.device = device\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "    def load_model(self, mdl_kwargs, model_path, device):\n",
    "        model = torch.jit.load(model_path, map_location=device)\n",
    "        return model\n",
    "\n",
    "    def __call__(self, frame_feats):\n",
    "        feat = torch.from_numpy(frame_feats).unsqueeze(0)\n",
    "        feat = feat.float().to(self.device)\n",
    "        with torch.no_grad():\n",
    "            embd = self.model(feat)\n",
    "        embd = embd.squeeze(0).cpu().numpy()\n",
    "        return embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf_jit = JITExtractor(mdl_clf_kwargs, '821b_jit.pt', 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = softmax(model_clf_jit(sample_feats))\n",
    "top_pred = np.argmax(logits)\n",
    "confidence = logits[top_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992602"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AmurFalcon'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2label[top_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
